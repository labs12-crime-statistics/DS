{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (19.1)\n",
      "Requirement already satisfied: python-decouple in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (3.1)\n",
      "Requirement already satisfied: geoalchemy2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (0.6.2)\n",
      "Requirement already satisfied: SQLAlchemy>=0.8 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from geoalchemy2) (1.2.11)\n",
      "Requirement already satisfied: shapely in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (1.6.4.post2)\n",
      "Requirement already up-to-date: imbalanced-learn in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (0.4.3)\n",
      "Requirement already satisfied, skipping upgrade: scipy>=0.13.3 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from imbalanced-learn) (1.1.0)\n",
      "Requirement already satisfied, skipping upgrade: numpy>=1.8.2 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from imbalanced-learn) (1.15.4)\n",
      "Requirement already satisfied, skipping upgrade: scikit-learn>=0.20 in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (from imbalanced-learn) (0.20.3)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages (1.1.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install python-decouple\n",
    "!pip install geoalchemy2\n",
    "!pip install shapely\n",
    "!pip install -U imbalanced-learn\n",
    "!pip install scipy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, func, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from decouple import config\n",
    "from shapely import wkb, wkt\n",
    "from shapely.geometry import Point\n",
    "from geoalchemy2.shape import to_shape \n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense\n",
    "\n",
    "# ----------- TODO: Issues with importing imbalance-learn library\n",
    "# from imblearn.over_sampling import RandomOverSampler\n",
    "# from imblearn.under_sampling import NearMiss\n",
    "# from imblearn.under_sampling import (RandomUnderSampler,\n",
    "#                                      ClusterCentroids,\n",
    "#                                      TomekLinks,\n",
    "#                                      NeighbourhoodCleaningRule,\n",
    "#                                      NearMiss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Contains models for DB.\"\"\"\n",
    "\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, BigInteger, Integer, String, DateTime, ForeignKey, Float\n",
    "from sqlalchemy.orm import relationship\n",
    "from geoalchemy2 import Geometry\n",
    "\n",
    "\n",
    "BASE = declarative_base()\n",
    "\n",
    "\n",
    "class City(BASE):\n",
    "    \"\"\"City model for DB. Has information of cities.\"\"\"\n",
    "    __tablename__ = 'city'\n",
    "    id            = Column(BigInteger, primary_key=True)\n",
    "    city          = Column(String, unique=False, nullable=False)\n",
    "    state         = Column(String, unique=False, nullable=True)\n",
    "    country       = Column(String, unique=False, nullable=False)\n",
    "    location      = Column(Geometry(geometry_type='POINT'), nullable=False)\n",
    "    blocks        = relationship(\"Blocks\", back_populates=\"city\")\n",
    "    zipcodes      = relationship(\"ZipcodeGeom\", back_populates=\"city\")\n",
    "    incidents     = relationship(\"Incident\", back_populates=\"city\")\n",
    "\n",
    "\n",
    "class Blocks(BASE):\n",
    "    \"\"\"Block model for DB. Has information of city blocks for a related city\n",
    "        id.\"\"\"\n",
    "    __tablename__ = 'block'\n",
    "    id            = Column(BigInteger, primary_key=True)\n",
    "    cityid        = Column(BigInteger, ForeignKey('city.id'), nullable=False)\n",
    "    shape         = Column(Geometry(geometry_type='MULTIPOLYGON'), nullable=False)\n",
    "    population    = Column(Integer, nullable=False)\n",
    "    city          = relationship(\"City\", back_populates=\"blocks\")\n",
    "    incidents     = relationship(\"Incident\", back_populates=\"block\")\n",
    "\n",
    "class ZipcodeGeom(BASE):\n",
    "    \"\"\"Zipcode geometry model for DB. Has information of zipcodes and related\n",
    "        city id.\"\"\"\n",
    "    __tablename__ = 'zipcodegeom'\n",
    "    id            = Column(BigInteger, primary_key=True)\n",
    "    cityid        = Column(BigInteger, ForeignKey('city.id'), nullable=False)\n",
    "    zipcode       = Column(String, nullable=False, unique=True)\n",
    "    shape         = Column(Geometry(geometry_type='MULTIPOLYGON'), nullable=False)\n",
    "    city          = relationship(\"City\", back_populates=\"zipcodes\")\n",
    "\n",
    "class Incident(BASE):\n",
    "    \"\"\"Incident model for DB. Has information of a specific crime, including\n",
    "        where it took place, when it took place, and the type of crime that\n",
    "        occurred.\"\"\"\n",
    "    __tablename__ = 'incident'\n",
    "    id            = Column(BigInteger, primary_key=True)\n",
    "    crimetypeid   = Column(BigInteger, ForeignKey('crimetype.id'), nullable=False)\n",
    "    locdescid     = Column(BigInteger, ForeignKey('locdesctype.id'), nullable=False)\n",
    "    cityid        = Column(BigInteger, ForeignKey('city.id'), nullable=False)\n",
    "    blockid       = Column(BigInteger, ForeignKey('block.id'), nullable=False)\n",
    "    location      = Column(Geometry(geometry_type='POINT'), nullable=False)\n",
    "    datetime      = Column(DateTime, nullable=False)\n",
    "    hour          = Column(Integer, nullable=False)\n",
    "    dow           = Column(Integer, nullable=False)\n",
    "    month         = Column(Integer, nullable=False)\n",
    "    year          = Column(Integer, nullable=False)\n",
    "    city          = relationship(\"City\", back_populates=\"incidents\")\n",
    "    block         = relationship(\"Blocks\", back_populates=\"incidents\")\n",
    "    crimetype     = relationship(\"CrimeType\", back_populates=\"incidents\")\n",
    "    locationdesc  = relationship(\"LocationDescriptionType\", back_populates=\"incidents\")\n",
    "\n",
    "class CrimeType(BASE):\n",
    "    \"\"\"CrimeType model for DB. Has information of the types of crime, including\n",
    "        a general description and the numerical severity of the crime.\"\"\"\n",
    "    __tablename__ = 'crimetype'\n",
    "    id            = Column(BigInteger, primary_key=True)\n",
    "    category      = Column(String, unique=True, nullable=False)\n",
    "    severity      = Column(Integer, nullable=False)\n",
    "    incidents     = relationship(\"Incident\", back_populates=\"crimetype\")\n",
    "\n",
    "\n",
    "class LocationDescriptionType(BASE):\n",
    "    \"\"\"Location description model for DB. Has information on the type of\n",
    "        location that the crime took place.\"\"\"\n",
    "    __tablename__ = 'locdesctype'\n",
    "    id            = Column(BigInteger, primary_key=True)\n",
    "    key1          = Column(String, nullable=False)\n",
    "    key2          = Column(String, nullable=False)\n",
    "    key3          = Column(String, nullable=False)\n",
    "    incidents     = relationship(\"Incident\", back_populates=\"locationdesc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow_p36/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    }
   ],
   "source": [
    "# Connect to DB and create session with DB\n",
    "DB_URI  = config('DB_URI')\n",
    "ENGINE  = create_engine(DB_URI)\n",
    "Session = sessionmaker(bind=ENGINE)\n",
    "SESSION = Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(start_year, end_year):\n",
    "    SQL_QUERY = \\\n",
    "        f'''\n",
    "            WITH\n",
    "                max_severity AS (\n",
    "                    SELECT MAX(severity) AS severity\n",
    "                    FROM (\n",
    "                        SELECT SUM(crimetype.severity)/AVG(block.population) AS severity\n",
    "                        FROM incident\n",
    "                        INNER JOIN block ON incident.blockid = block.id INNER JOIN crimetype ON incident.crimetypeid = crimetype.id AND block.population > 0\n",
    "                        GROUP BY\n",
    "                            incident.blockid,\n",
    "                            incident.year,\n",
    "                            incident.month,\n",
    "                            incident.dow,\n",
    "                            incident.hour\n",
    "                    ) AS categories\n",
    "                ),\n",
    "                block_incidents AS (\n",
    "                    SELECT\n",
    "                        incident.blockid,\n",
    "                        incident.year,\n",
    "                        incident.month,\n",
    "                        incident.dow,\n",
    "                        incident.hour,\n",
    "                        SUM(crimetype.severity)/AVG(block.population) AS severity\n",
    "                    FROM incident\n",
    "                    INNER JOIN block ON incident.blockid = block.id\n",
    "                    INNER JOIN crimetype ON incident.crimetypeid = crimetype.id\n",
    "                        AND block.population > 0\n",
    "                        AND incident.cityid = 1\n",
    "                        AND incident.year >= {start_year}\n",
    "                        AND incident.year <= {end_year}\n",
    "                    GROUP BY\n",
    "                        incident.blockid,\n",
    "                        incident.year,\n",
    "                        incident.month,\n",
    "                        incident.dow,\n",
    "                        incident.hour\n",
    "                )\n",
    "            SELECT\n",
    "                block_incidents.blockid,\n",
    "                block_incidents.year,\n",
    "                block_incidents.month,\n",
    "                block_incidents.dow,\n",
    "                block_incidents.hour,\n",
    "                block_incidents.severity / max_severity.severity AS severity\n",
    "            FROM block_incidents, max_severity        \n",
    "        '''\n",
    "    \n",
    "    ENGINE  = create_engine(DB_URI)\n",
    "    Session = sessionmaker(bind=ENGINE)\n",
    "    SESSION = Session()\n",
    "    return SESSION.execute(text(SQL_QUERY)).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data(data, start_year, end_year):\n",
    "    df = pd.DataFrame.from_records(data, \n",
    "                                  columns=['lat', 'long', 'datetime',\n",
    "                                           'year', 'month', \n",
    "                                           'dow', 'hour',\n",
    "                                           'pop', 'severity'])\n",
    "    df_full = create_full_dataset(df, start_year, end_year)\n",
    "    \n",
    "    print('df_full.shape:', df_full.shape)\n",
    "    print(df_full.head())\n",
    "        \n",
    "    # shuffle data\n",
    "    df_full = df_full.sample(frac=1)\n",
    "    \n",
    "    print('separate X and y')\n",
    "    # separate X and y\n",
    "    y = df_full['risk']\n",
    "    X = df_full.drop(columns=['risk'])\n",
    "\n",
    "    print('RobustScaler')\n",
    "    # All neural networks require floating point data.\n",
    "    # The scaler converts ints to floats.\n",
    "    # We use the RobustScaler since it keeps the data\n",
    "    # more spread out than the StandardScaler.\n",
    "    # Check out the figures here:\n",
    "    # https://scikit-learn.org/stable/auto_examples/preprocessing/plot_all_scaling.html\n",
    "    X = RobustScaler().fit_transform(X)\n",
    "    \n",
    "    print('\\n', X[:10], '\\n')\n",
    "    print('\\n', y.head(), '\\n')\n",
    "    \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ready_data(training_start_year, training_end_year,\n",
    "                testing_start_year, testing_end_year):\n",
    "    \n",
    "    # Get data from database\n",
    "    training_data = get_data(training_start_year, training_end_year)\n",
    "\n",
    "    NUM_BLOCKIDS = 20\n",
    "    \n",
    "    X = np.zeros((NUM_BLOCKIDS, 24, 7*24))\n",
    "    y = np.zeros((NUM_BLOCKIDS, 12, 7*24))\n",
    "    blockid_dict = {}\n",
    "\n",
    "    # Create random array (BLOCKIDS) from 1-801 inclusive\n",
    "    # of length NUM_BLOCKIDS\n",
    "    BLOCKIDS = random.choices(list(range(1,802)), k=NUM_BLOCKIDS)\n",
    "\n",
    "    for ind, blockid in enumerate(BLOCKIDS):\n",
    "        blockid_dict[blockid] = ind\n",
    "\n",
    "    # records is the list of rows we get from the query with this order:\n",
    "    #   blockid, year, month, dow, hour, risk\n",
    "    #   month is from 1 - 12\n",
    "\n",
    "    for r in training_data:\n",
    "        if r[0] in blockid_dict:\n",
    "            if r[1] == testing_start_year:\n",
    "                # index into array  0-based month\n",
    "                # vvvvvvvvvvvvvvvv    vvvvvv\n",
    "                y[blockid_dict[r[0]], r[2]-1, 24*r[3]+r[4]] = r[5]\n",
    "                #                             ^^^^^^^^^^^^^   ^^^^\n",
    "                #                             hours since     risk\n",
    "                #                             beginning of\n",
    "                #                             week\n",
    "            else:\n",
    "                # index into array    year 0.....1   month   \n",
    "                # vvvvvvvvvvvvvvvv    vvvvvvvvvvvvv  vvvvvv\n",
    "                X[blockid_dict[r[0]], 12*(r[1]-training_start_year)+r[2]-1, 24*r[3]+r[4]] = r[5]\n",
    "                #                                                           ^^^^^^^^^^^^^   ^^^^\n",
    "                #                                                           hours since     risk\n",
    "                #                                                           beginning of\n",
    "                #                                                           week                \n",
    "            \n",
    "    return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "X_train, y_train = ready_data(2016, 2017, 2018, 2018)\n",
    "# X_train, X_test, y_train, y_test = ready_data(2016, 2017, 2018, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape, y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train[:, 0, 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, Reshape\n",
    "\n",
    "data_dim    = 7 * 24   # All values in each hour of the week\n",
    "timesteps   = 2 * 12   # Summed per month\n",
    "batch_size  = 64\n",
    "num_outputs = 7 * 24 * 12\n",
    "\n",
    "# expected input data shape: (batch_size, timesteps, data_dim)\n",
    "model = Sequential()\n",
    "model.add(LSTM(128, input_shape=(timesteps, data_dim)))  # returns a sequence of vectors of dimension 32.\n",
    "model.add(Dense(num_outputs, activation='relu'))         # Leaky-ReLU and ReLU are the same for Keras\n",
    "model.add(Reshape((12, 7 * 24)))\n",
    "\n",
    "model.compile(loss='mean_squared_error',\n",
    "              optimizer='adam')\n",
    "\n",
    "model.fit(X_train, y_train,\n",
    "          batch_size=batch_size, epochs=5)\n",
    "\n",
    "score = model.evaluate(X_train, y_train,\n",
    "                       batch_size=batch_size)\n",
    "print('Train score:', score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train - model.predict(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_tensorflow_p36",
   "language": "python",
   "name": "conda_tensorflow_p36"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
