{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already up-to-date: pip in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (19.1.1)\n",
      "Requirement already satisfied: python-decouple in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (3.1)\n",
      "Requirement already satisfied: geoalchemy2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.6.2)\n",
      "Requirement already satisfied: SQLAlchemy>=0.8 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from geoalchemy2) (1.2.11)\n",
      "Requirement already satisfied: shapely in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.6.4.post2)\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (1.1.0)\n",
      "Requirement already satisfied: category-encoders in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (2.0.0)\n",
      "Requirement already satisfied: patsy>=0.4.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (0.5.0)\n",
      "Requirement already satisfied: numpy>=1.11.3 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (1.15.4)\n",
      "Requirement already satisfied: pandas>=0.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (0.22.0)\n",
      "Requirement already satisfied: statsmodels>=0.6.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (0.9.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.20.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from category-encoders) (0.20.3)\n",
      "Requirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from patsy>=0.4.1->category-encoders) (1.11.0)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.21.1->category-encoders) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.21.1->category-encoders) (2.7.3)\n"
     ]
    }
   ],
   "source": [
    "!pip install --upgrade pip\n",
    "!pip install python-decouple\n",
    "!pip install geoalchemy2\n",
    "!pip install shapely\n",
    "!pip install scipy\n",
    "!pip install category-encoders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: xgboost in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.82)\r\n",
      "Requirement already satisfied: numpy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.15.4)\r\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from xgboost) (1.1.0)\r\n"
     ]
    }
   ],
   "source": [
    "from sqlalchemy import create_engine, func, text\n",
    "from sqlalchemy.orm import sessionmaker\n",
    "from decouple import config\n",
    "from shapely import wkb, wkt\n",
    "from shapely.geometry import Point\n",
    "from geoalchemy2.shape import to_shape \n",
    "!pip install xgboost\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "import json\n",
    "from datetime import datetime, timedelta\n",
    "import re\n",
    "from matplotlib import pyplot as plt\n",
    "import pickle\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.metrics import mean_absolute_error, \\\n",
    "                            mean_squared_error\n",
    "from xgboost import XGBRegressor\n",
    "\n",
    "pd.options.display.max_columns = None\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from category_encoders import BinaryEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: tpot in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (0.10.1)\n",
      "Requirement already satisfied: stopit>=1.1.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tpot) (1.1.2)\n",
      "Requirement already satisfied: numpy>=1.12.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tpot) (1.15.4)\n",
      "Requirement already satisfied: deap>=1.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tpot) (1.2.2)\n",
      "Requirement already satisfied: update-checker>=0.16 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tpot) (0.16)\n",
      "Requirement already satisfied: pandas>=0.20.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tpot) (0.22.0)\n",
      "Requirement already satisfied: scipy>=0.19.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tpot) (1.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tpot) (0.20.3)\n",
      "Requirement already satisfied: tqdm>=4.26.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from tpot) (4.31.1)\n",
      "Requirement already satisfied: requests>=2.3.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from update-checker>=0.16->tpot) (2.20.1)\n",
      "Requirement already satisfied: pytz>=2011k in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.20.2->tpot) (2018.4)\n",
      "Requirement already satisfied: python-dateutil>=2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from pandas>=0.20.2->tpot) (2.7.3)\n",
      "Requirement already satisfied: idna<2.8,>=2.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2.6)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (2019.3.9)\n",
      "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (1.23)\n",
      "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from requests>=2.3.0->update-checker>=0.16->tpot) (3.0.4)\n",
      "Requirement already satisfied: six>=1.5 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from python-dateutil>=2->pandas>=0.20.2->tpot) (1.11.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install tpot\n",
    "from tpot import TPOTRegressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"Contains models for DB.\"\"\"\n",
    "\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy import Column, BigInteger, Integer, String, DateTime, ForeignKey, Float\n",
    "from sqlalchemy.orm import relationship\n",
    "from geoalchemy2 import Geometry\n",
    "\n",
    "\n",
    "BASE = declarative_base()\n",
    "\n",
    "\n",
    "class City(BASE):\n",
    "    \"\"\"City model for DB. Has information of cities.\"\"\"\n",
    "    __tablename__ = 'city'\n",
    "    id            = Column(BigInteger, primary_key=True)\n",
    "    city          = Column(String, unique=False, nullable=False)\n",
    "    state         = Column(String, unique=False, nullable=True)\n",
    "    country       = Column(String, unique=False, nullable=False)\n",
    "    location      = Column(Geometry(geometry_type='POINT'), nullable=False)\n",
    "    blocks        = relationship(\"Blocks\", back_populates=\"city\")\n",
    "    zipcodes      = relationship(\"ZipcodeGeom\", back_populates=\"city\")\n",
    "    incidents     = relationship(\"Incident\", back_populates=\"city\")\n",
    "\n",
    "\n",
    "class Blocks(BASE):\n",
    "    \"\"\"Block model for DB. Has information of city blocks for a related city\n",
    "        id.\"\"\"\n",
    "    __tablename__ = 'block'\n",
    "    id            = Column(BigInteger, primary_key=True)\n",
    "    cityid        = Column(BigInteger, ForeignKey('city.id'), nullable=False)\n",
    "    shape         = Column(Geometry(geometry_type='MULTIPOLYGON'), nullable=False)\n",
    "    population    = Column(Integer, nullable=False)\n",
    "    city          = relationship(\"City\", back_populates=\"blocks\")\n",
    "    incidents     = relationship(\"Incident\", back_populates=\"block\")\n",
    "\n",
    "class ZipcodeGeom(BASE):\n",
    "    \"\"\"Zipcode geometry model for DB. Has information of zipcodes and related\n",
    "        city id.\"\"\"\n",
    "    __tablename__ = 'zipcodegeom'\n",
    "    id            = Column(BigInteger, primary_key=True)\n",
    "    cityid        = Column(BigInteger, ForeignKey('city.id'), nullable=False)\n",
    "    zipcode       = Column(String, nullable=False, unique=True)\n",
    "    shape         = Column(Geometry(geometry_type='MULTIPOLYGON'), nullable=False)\n",
    "    city          = relationship(\"City\", back_populates=\"zipcodes\")\n",
    "\n",
    "class Incident(BASE):\n",
    "    \"\"\"Incident model for DB. Has information of a specific crime, including\n",
    "        where it took place, when it took place, and the type of crime that\n",
    "        occurred.\"\"\"\n",
    "    __tablename__ = 'incident'\n",
    "    id            = Column(BigInteger, primary_key=True)\n",
    "    crimetypeid   = Column(BigInteger, ForeignKey('crimetype.id'), nullable=False)\n",
    "    locdescid     = Column(BigInteger, ForeignKey('locdesctype.id'), nullable=False)\n",
    "    cityid        = Column(BigInteger, ForeignKey('city.id'), nullable=False)\n",
    "    blockid       = Column(BigInteger, ForeignKey('block.id'), nullable=False)\n",
    "    location      = Column(Geometry(geometry_type='POINT'), nullable=False)\n",
    "    datetime      = Column(DateTime, nullable=False)\n",
    "    hour          = Column(Integer, nullable=False)\n",
    "    dow           = Column(Integer, nullable=False)\n",
    "    month         = Column(Integer, nullable=False)\n",
    "    year          = Column(Integer, nullable=False)\n",
    "    city          = relationship(\"City\", back_populates=\"incidents\")\n",
    "    block         = relationship(\"Blocks\", back_populates=\"incidents\")\n",
    "    crimetype     = relationship(\"CrimeType\", back_populates=\"incidents\")\n",
    "    locationdesc  = relationship(\"LocationDescriptionType\", back_populates=\"incidents\")\n",
    "\n",
    "class CrimeType(BASE):\n",
    "    \"\"\"CrimeType model for DB. Has information of the types of crime, including\n",
    "        a general description and the numerical severity of the crime.\"\"\"\n",
    "    __tablename__ = 'crimetype'\n",
    "    id            = Column(BigInteger, primary_key=True)\n",
    "    category      = Column(String, unique=True, nullable=False)\n",
    "    severity      = Column(Integer, nullable=False)\n",
    "    incidents     = relationship(\"Incident\", back_populates=\"crimetype\")\n",
    "\n",
    "\n",
    "class LocationDescriptionType(BASE):\n",
    "    \"\"\"Location description model for DB. Has information on the type of\n",
    "        location that the crime took place.\"\"\"\n",
    "    __tablename__ = 'locdesctype'\n",
    "    id            = Column(BigInteger, primary_key=True)\n",
    "    key1          = Column(String, nullable=False)\n",
    "    key2          = Column(String, nullable=False)\n",
    "    key3          = Column(String, nullable=False)\n",
    "    incidents     = relationship(\"Incident\", back_populates=\"locationdesc\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GetDataFull(object):\n",
    "    def go(self, SESSION, start_year, end_year):\n",
    "        SQL_QUERY = \\\n",
    "            f'''\n",
    "            SELECT incident.blockid,\n",
    "                    incident.datetime,\n",
    "                    incident.year, \n",
    "                    incident.month, \n",
    "                    incident.dow, \n",
    "                    incident.hour,\n",
    "                    SUM(crimetype.severity)/AVG(block.population) AS severity\n",
    "            FROM incident\n",
    "            INNER JOIN block ON incident.blockid = block.id INNER JOIN crimetype ON incident.crimetypeid = crimetype.id AND block.population > 0\n",
    "                AND block.population > 0\n",
    "                AND severity > 0\n",
    "                AND incident.cityid = 1\n",
    "                AND incident.year >= {start_year}\n",
    "                AND incident.year <= {end_year}\n",
    "            GROUP BY\n",
    "                incident.blockid,\n",
    "                incident.datetime,\n",
    "                incident.year,\n",
    "                incident.month,\n",
    "                incident.dow,\n",
    "                incident.hour\n",
    "            '''\n",
    "        return SESSION.execute(text(SQL_QUERY)).fetchall()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def days_in_month(year, month):\n",
    "    p = pd.Period(f'{year}-{month}-1')\n",
    "    return p.days_in_month\n",
    "\n",
    "def day_of_week(dt):\n",
    "    return dt.weekday()\n",
    "\n",
    "def create_arrays(blockids, start_year, end_year):\n",
    "    idx = 0\n",
    "    X_blockid, X_datetime, X_year, X_month, X_day, X_dow, X_hour, X_risk = [], [], [], [], [], [], [], []\n",
    "    for blockid in blockids:\n",
    "        for year in range(start_year, end_year + 1):\n",
    "            for month in range(1, 12 + 1):      # month range is 1-12\n",
    "                for day in range(1, days_in_month(year, month) + 1):\n",
    "                    for hour in range(24):      # hour range is 0-23\n",
    "                        X_blockid.append(blockid)\n",
    "                        X_datetime.append(datetime(year, month, day, hour, 0, 0, 0))\n",
    "                        X_year.append(year)\n",
    "                        X_month.append(month)\n",
    "                        X_day.append(day)\n",
    "                        X_dow.append(day_of_week(datetime(year, month, day)))\n",
    "                        X_hour.append(hour)\n",
    "                        X_risk.append(0.0)\n",
    "                        idx += 1\n",
    "    \n",
    "    X = pd.DataFrame({'blockid':  X_blockid,\n",
    "                      'datetime': X_datetime,\n",
    "                      'year':     X_year,\n",
    "                      'month':    X_month,\n",
    "                      'day':      X_day,\n",
    "                      'dow':      X_dow,\n",
    "                      'hour':     X_hour,\n",
    "                      'risk':     X_risk})\n",
    "\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_data_full(data, start_year, end_year):\n",
    "\n",
    "    def remove_outliers_from_risk(risk):\n",
    "        std = np.std(risk)\n",
    "        risk = np.where(risk < 20*std, \n",
    "                     risk, \n",
    "                     [0.]*len(risk)).reshape(risk.shape)\n",
    "\n",
    "        return risk\n",
    "    \n",
    "    def binary_encode_blockids(X):\n",
    "        encoded_blockids = pd.DataFrame(BinaryEncoder(cols=['blockid']) \\\n",
    "                                        .fit_transform(X))\n",
    "        \n",
    "        X = pd.concat([X, encoded_blockids], axis=1,\n",
    "                      names=['blockid' + str(i) for i in range(1, 801 +1)])\n",
    "        X = X.drop(columns=['blockid'])\n",
    "        return X\n",
    "    \n",
    "    NUM_BLOCKIDS = 801\n",
    "    \n",
    "    delta_years = end_year - start_year + 1\n",
    "    \n",
    "    X = create_arrays(range(1, NUM_BLOCKIDS + 1), start_year, end_year)\n",
    "    X = X.drop(columns=['year', 'month', 'day', 'dow', 'hour'], axis=1)\n",
    "\n",
    "    # records is the list of rows we get from the query with this order:\n",
    "    #   blockid, datetime, year, month, dow, hour, risk\n",
    "    #   month is from 1 - 12\n",
    "    \n",
    "    X1 = []\n",
    "    for r in data:\n",
    "        X1.append((r[0], r[1], r[6]))\n",
    "\n",
    "    X1 = pd.DataFrame(data=X1,\n",
    "                      columns=['blockid', 'datetime', 'risk2'])\n",
    "    X1['risk2'] = remove_outliers_from_risk(X1['risk2'].astype(float))\n",
    "    \n",
    "    return X1, X\n",
    "\n",
    "#     X = pd.merge(X, X1, \n",
    "#                  how='left',\n",
    "#                  left_on=['blockid', 'datetime'],\n",
    "#                  right_on=['blockid', 'datetime']\n",
    "#                 )\n",
    "#     X['all_risk'] = X.risk.astype(float) + X.risk2.astype(float)\n",
    "#     df = X.drop(columns=['risk', 'risk2']) \\\n",
    "#          .rename(mapper={'all_risk': 'risk'}, axis=1)\n",
    "    \n",
    "#     y = df['risk'].copy()\n",
    "#     df = df.drop(columns=['risk'])\n",
    "    \n",
    "#     y = remove_outliers_from_risk(y)\n",
    "#     df = binary_encode_blockids(df)\n",
    "#     df['risk'] = y\n",
    "#     df1 = df.iloc[:, :-2]\n",
    "#     df2 = df.iloc[:, -1]\n",
    "#     df = pd.concat([df1, df2], axis=1)\n",
    "    \n",
    "#     return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from contextlib import contextmanager\n",
    "\n",
    "@contextmanager\n",
    "def session_scope():\n",
    "    \"\"\"Provide a transactional scope around a series of operations.\"\"\"\n",
    "\n",
    "    DB_URI  = config('DB_URI')\n",
    "    ENGINE  = create_engine(DB_URI)\n",
    "    Session = sessionmaker(bind=ENGINE)\n",
    "    SESSION = Session()\n",
    "    \n",
    "    try:\n",
    "        yield SESSION\n",
    "        SESSION.commit()\n",
    "    except:\n",
    "        SESSION.rollback()\n",
    "        raise\n",
    "    finally:\n",
    "        SESSION.close()\n",
    "\n",
    "\n",
    "def ready_data_full(training_start_year, training_end_year,\n",
    "                    testing_start_year, testing_end_year):\n",
    "    with session_scope() as session:\n",
    "        training_data = GetDataFull().go(session,\n",
    "                                         training_start_year,\n",
    "                                         training_end_year)\n",
    "        testing_data = GetDataFull().go(session,\n",
    "                                         testing_start_year,\n",
    "                                         testing_end_year)\n",
    "        train, train_generated = process_data_full(training_data,\n",
    "                                                 training_start_year, \n",
    "                                                 training_end_year)\n",
    "        test, test_generated = process_data_full(testing_data,\n",
    "                                               testing_start_year, \n",
    "                                               testing_end_year)\n",
    "\n",
    "    return train, test, train_generated, test_generated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages/psycopg2/__init__.py:144: UserWarning: The psycopg2 wheel package will be renamed from release 2.8; in order to keep installing from binary please use \"pip install psycopg2-binary\" instead. For details see: <http://initd.org/psycopg/docs/install.html#binary-install-from-pypi>.\n",
      "  \"\"\")\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 27s, sys: 7.91 s, total: 1min 35s\n",
      "Wall time: 1min 41s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "train, test, train_generated, test_generated = ready_data_full(2015, 2016, 2017, 2018)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((507148, 3), (508511, 3), (14052744, 3), (14033520, 3))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.shape, test.shape, train_generated.shape, test_generated.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blockid</th>\n",
       "      <th>datetime</th>\n",
       "      <th>risk2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-02 10:30:00</td>\n",
       "      <td>0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-03 09:40:00</td>\n",
       "      <td>0.000303</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-03 22:30:00</td>\n",
       "      <td>0.001816</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blockid            datetime     risk2\n",
       "0        1 2015-01-01 00:00:00  0.000605\n",
       "1        1 2015-01-01 02:00:00  0.000908\n",
       "2        1 2015-01-02 10:30:00  0.000605\n",
       "3        1 2015-01-03 09:40:00  0.000303\n",
       "4        1 2015-01-03 22:30:00  0.001816"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train2 = train.set_index('datetime')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blockid</th>\n",
       "      <th>datetime</th>\n",
       "      <th>risk</th>\n",
       "      <th>risk2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 00:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 01:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 02:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 03:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>2015-01-01 04:00:00</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blockid            datetime  risk     risk2\n",
       "0        1 2015-01-01 00:00:00   0.0  0.000605\n",
       "1        1 2015-01-01 01:00:00   0.0       NaN\n",
       "2        1 2015-01-01 02:00:00   0.0  0.000908\n",
       "3        1 2015-01-01 03:00:00   0.0       NaN\n",
       "4        1 2015-01-01 04:00:00   0.0       NaN"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "group = train2.groupby('blockid')\n",
    "# for k in group.groups.keys():\n",
    "#     g = group.get_group(k)\n",
    "g = group.get_group(1)\n",
    "g['risk2'].reset_index(drop=True)\n",
    "df2 = pd.merge(train_generated, g.reset_index(), \n",
    "                 how='left',\n",
    "                 left_on=['blockid', 'datetime'],\n",
    "                 right_on=['blockid', 'datetime']\n",
    "                )\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blockid              int64\n",
       "datetime    datetime64[ns]\n",
       "risk               float64\n",
       "risk2              float64\n",
       "dtype: object"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.dtypes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blockid</th>\n",
       "      <th>datetime</th>\n",
       "      <th>risk</th>\n",
       "      <th>risk2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1420074000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1420077600</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1420081200</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1420084800</td>\n",
       "      <td>0.0</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blockid    datetime  risk     risk2\n",
       "0        1  1420070400   0.0  0.000605\n",
       "1        1  1420074000   0.0       NaN\n",
       "2        1  1420077600   0.0  0.000908\n",
       "3        1  1420081200   0.0       NaN\n",
       "4        1  1420084800   0.0       NaN"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2['datetime']= pd.to_timedelta(df2.datetime).dt.total_seconds().astype(int)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blockid</th>\n",
       "      <th>datetime</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1420074000</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>1420077600</td>\n",
       "      <td>0.000908</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1420081200</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>1420084800</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   blockid    datetime      risk\n",
       "0        1  1420070400  0.000605\n",
       "1        1  1420074000  0.000000\n",
       "2        1  1420077600  0.000908\n",
       "3        1  1420081200  0.000000\n",
       "4        1  1420084800  0.000000"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2 = df2.fillna(value=0)\n",
    "df2['all_risk'] = df2['risk'] + df2['risk2']\n",
    "df2 = df2.drop(columns=['risk', 'risk2']) \\\n",
    "            .rename(mapper={'all_risk': 'risk'}, axis=1)\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>blockid</th>\n",
       "      <th>datetime</th>\n",
       "      <th>risk</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>0.000605</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17544</th>\n",
       "      <td>2</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>35088</th>\n",
       "      <td>3</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>52632</th>\n",
       "      <td>4</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>70176</th>\n",
       "      <td>5</td>\n",
       "      <td>1420070400</td>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       blockid    datetime      risk\n",
       "0            1  1420070400  0.000605\n",
       "17544        2  1420070400  0.000000\n",
       "35088        3  1420070400  0.000000\n",
       "52632        4  1420070400  0.000000\n",
       "70176        5  1420070400  0.000000"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df2.sort_values(by=['datetime', 'blockid'], inplace=True, ascending=[True, True])\n",
    "df2.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train.shape: (10539558, 2) y_train.shape: (10539558,)\n",
      "X_val.shape: (3513186, 2) y_val.shape: (3513186,)\n"
     ]
    }
   ],
   "source": [
    "def split_train_validate(df, target_name, test_fraction=0.25):\n",
    "\n",
    "    test_size = int(df.shape[0] * test_fraction)\n",
    "    df_train = df.iloc[:df.shape[0]-test_size,  :]\n",
    "    df_val   = df.iloc[ df.shape[0]-test_size:, :]\n",
    "    X_train  = df_train.drop(columns=[target_name])\n",
    "    y_train  = df_train[target_name]\n",
    "    X_val    = df_val.drop(columns=[target_name])\n",
    "    y_val    = df_val[target_name]\n",
    "\n",
    "    print('X_train.shape:', X_train.shape, 'y_train.shape:', y_train.shape)\n",
    "    print('X_val.shape:', X_val.shape, 'y_val.shape:', y_val.shape)\n",
    "    \n",
    "    return X_train, X_val, y_train, y_val\n",
    "\n",
    "X_train, X_val, y_train, y_val = split_train_validate(df2, \n",
    "                                                     'risk', \n",
    "                                                     0.25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average of the training y against validation y gives MAE: 6.012492017674962e-08\n",
      "Average of the training y against itself gives MAE: 5.438305972121914e-08\n"
     ]
    }
   ],
   "source": [
    "def baseline(y_train, y_val):\n",
    "    \n",
    "    mean_value_train = y_train.mean()\n",
    "    \n",
    "    y_pred = [abs(y - mean_value_train) for y in y_val]\n",
    "    mean_value_ypred = np.average(y_pred)\n",
    "    mae = np.average([abs(y - mean_value_ypred) for y in y_pred], axis = 0)\n",
    "    return mae\n",
    "\n",
    "print('Average of the training y against validation y gives MAE:', baseline(y_train, y_val))\n",
    "print('Average of the training y against itself gives MAE:', baseline(y_train, y_train))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0018159806295399517\n",
      "2.7912827272782475e-08\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "print(df2['risk'].max())\n",
    "print(df2['risk'].mean())\n",
    "print(df2['risk'].median())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=110, style=ProgressStyle(descript…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: -1.9946394071306894e-11\n",
      "Generation 2 - Current best internal CV score: -1.9946394071306894e-11\n",
      "Generation 3 - Current best internal CV score: -1.9946394071306894e-11\n",
      "Generation 4 - Current best internal CV score: -1.9946394071306894e-11\n",
      "Generation 5 - Current best internal CV score: -1.9946394071306894e-11\n",
      "Generation 6 - Current best internal CV score: -1.9946394071306894e-11\n",
      "Generation 7 - Current best internal CV score: -1.9946394071306894e-11\n",
      "Generation 8 - Current best internal CV score: -1.9946394071306894e-11\n",
      "Generation 9 - Current best internal CV score: -1.9946394071306894e-11\n",
      "Generation 10 - Current best internal CV score: -1.9946394071306894e-11\n",
      "\n",
      "Best pipeline: DecisionTreeRegressor(input_matrix, max_depth=8, min_samples_leaf=9, min_samples_split=13)\n",
      "-2.0363419573247403e-11\n",
      "CPU times: user 12h 21min 49s, sys: 17min 19s, total: 12h 39min 9s\n",
      "Wall time: 12h 27min 42s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "tpot = TPOTRegressor(generations=10, population_size=10, verbosity=2)\n",
    "tpot.fit(X_train, y_train)\n",
    "print(tpot.score(X_val, y_val))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_val_predict = tpot.predict(X_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MSE is 2.0363419573247403e-11\n",
      "RMSE is 4.512584577960551e-06\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "MSE = mean_squared_error(y_val, y_val_predict)\n",
    "RMSE = (np.sqrt(MSE))\n",
    "\n",
    "print('MSE is {}'.format(MSE))\n",
    "print('RMSE is {}'.format(RMSE))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "param_grid = {   \n",
    "    'learning_rate': [0.05],\n",
    "    'n_estimators':  [50],\n",
    "    'max_depth': [2],\n",
    "}\n",
    "gridsearch = GridSearchCV(XGBRegressor(),\n",
    "                          param_grid=param_grid, \n",
    "                          cv=3, n_jobs=-1,\n",
    "                          return_train_score=True, verbose=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 1 candidates, totalling 3 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend LokyBackend with 16 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  2.3min remaining:    0.0s\n",
      "[Parallel(n_jobs=-1)]: Done   3 out of   3 | elapsed:  2.3min finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "GridSearchCV(cv=3, error_score='raise-deprecating',\n",
       "       estimator=XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
       "       min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1),\n",
       "       fit_params=None, iid='warn', n_jobs=-1,\n",
       "       param_grid={'learning_rate': [0.05], 'n_estimators': [50], 'max_depth': [2]},\n",
       "       pre_dispatch='2*n_jobs', refit=True, return_train_score=True,\n",
       "       scoring=None, verbose=10)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "XGBRegressor(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
       "       colsample_bytree=1, gamma=0, importance_type='gain',\n",
       "       learning_rate=0.05, max_delta_step=0, max_depth=2,\n",
       "       min_child_weight=1, missing=None, n_estimators=50, n_jobs=1,\n",
       "       nthread=None, objective='reg:linear', random_state=0, reg_alpha=0,\n",
       "       reg_lambda=1, scale_pos_weight=1, seed=None, silent=True,\n",
       "       subsample=1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.best_estimator_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([-74672773.87127508])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gridsearch.cv_results_['mean_train_score']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 0.03847244355477365\n",
      "rmse: 0.03847244381942293\n"
     ]
    }
   ],
   "source": [
    "y_pred_gs = gridsearch.predict(X_val)\n",
    "print('mae:', mean_absolute_error(y_val, y_pred_gs))\n",
    "print('rmse:', np.sqrt(mean_squared_error(y_val, y_pred_gs)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting eli5\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ee/2b/246db9e1c2d6f38e999daf0c4d5e54f36fbd0b937ffb13a34d32c2139403/eli5-0.8.2-py2.py3-none-any.whl (98kB)\n",
      "\u001b[K     |████████████████████████████████| 102kB 4.3MB/s ta 0:00:011\n",
      "\u001b[?25hRequirement already satisfied: jinja2 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (2.10)\n",
      "Collecting tabulate>=0.7.7 (from eli5)\n",
      "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c2/fd/202954b3f0eb896c53b7b6f07390851b1fd2ca84aa95880d7ae4f434c4ac/tabulate-0.8.3.tar.gz (46kB)\n",
      "\u001b[K     |████████████████████████████████| 51kB 32.6MB/s eta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: six in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (1.11.0)\n",
      "Collecting graphviz (from eli5)\n",
      "  Downloading https://files.pythonhosted.org/packages/1f/e2/ef2581b5b86625657afd32030f90cf2717456c1d2b711ba074bf007c0f1a/graphviz-0.10.1-py2.py3-none-any.whl\n",
      "Requirement already satisfied: scipy in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (1.1.0)\n",
      "Requirement already satisfied: attrs>16.0.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (18.1.0)\n",
      "Requirement already satisfied: scikit-learn>=0.18 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (0.20.3)\n",
      "Requirement already satisfied: numpy>=1.9.0 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (1.15.4)\n",
      "Requirement already satisfied: typing in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from eli5) (3.6.4)\n",
      "Requirement already satisfied: MarkupSafe>=0.23 in /home/ec2-user/anaconda3/envs/python3/lib/python3.6/site-packages (from jinja2->eli5) (1.0)\n",
      "Building wheels for collected packages: tabulate\n",
      "  Building wheel for tabulate (setup.py) ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/ec2-user/.cache/pip/wheels/2b/67/89/414471314a2d15de625d184d8be6d38a03ae1e983dbda91e84\n",
      "Successfully built tabulate\n",
      "Installing collected packages: tabulate, graphviz, eli5\n",
      "Successfully installed eli5-0.8.2 graphviz-0.10.1 tabulate-0.8.3\n"
     ]
    }
   ],
   "source": [
    "!pip install eli5\n",
    "import eli5\n",
    "from eli5.sklearn import PermutationImportance\n",
    "\n",
    "from sklearn.ensemble import (\n",
    "    RandomForestRegressor, GradientBoostingRegressor)\n",
    "from sklearn.linear_model import LinearRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=None,\n",
       "         normalize=False)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "LRmodel = LinearRegression()\n",
    "LRmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 7.760622782725684e-08\n",
      "rmse: 4.512288868211553e-06\n"
     ]
    }
   ],
   "source": [
    "y_predLR = LRmodel.predict(X_val)\n",
    "print('mae:', mean_absolute_error(y_val, y_predLR))\n",
    "print('rmse:', np.sqrt(mean_squared_error(y_val, y_predLR)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime    1.933405e-16\n",
       "blockid    -2.034532e-10\n",
       "dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(LRmodel.coef_,\n",
    "          X_train.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "RFmodel = RandomForestRegressor(\n",
    "    n_estimators=100, \n",
    "    min_samples_leaf=0.004,\n",
    "    n_jobs=-1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=0.004, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "RFmodel.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 5.6881533606848086e-08\n",
      "rmse: 4.51258483386636e-06\n"
     ]
    }
   ],
   "source": [
    "y_predRF = RFmodel.predict(X_val)\n",
    "print('mae:', mean_absolute_error(y_val, y_predRF))\n",
    "print('rmse:', np.sqrt(mean_squared_error(y_val, y_predRF)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "datetime    0.0\n",
       "blockid     0.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(RFmodel.feature_importances_, \n",
    "          X_train.columns).sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PermutationImportance(cv='prefit',\n",
       "           estimator=RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "           max_features='auto', max_leaf_nodes=None,\n",
       "           min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "           min_samples_leaf=0.004, min_samples_split=2,\n",
       "           min_weight_fraction_leaf=0.0, n_estimators=100, n_jobs=-1,\n",
       "           oob_score=False, random_state=None, verbose=0, warm_start=False),\n",
       "           n_iter=1, random_state=None, refit=True,\n",
       "           scoring='neg_mean_squared_error')"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "permuter = PermutationImportance(RFmodel, scoring='neg_mean_squared_error', n_iter=1, cv='prefit')\n",
    "permuter.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\albeh\\Anaconda3\\lib\\site-packages\\eli5\\formatters\\html.py:234: RuntimeWarning: invalid value encountered in double_scalars\n",
      "  rel_weight = (abs(weight) / weight_range) ** 0.7\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "    <style>\n",
       "    table.eli5-weights tr:hover {\n",
       "        filter: brightness(85%);\n",
       "    }\n",
       "</style>\n",
       "\n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "        <table class=\"eli5-weights eli5-feature-importances\" style=\"border-collapse: collapse; border: none; margin-top: 0em; table-layout: auto;\">\n",
       "    <thead>\n",
       "    <tr style=\"border: none;\">\n",
       "        <th style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">Weight</th>\n",
       "        <th style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">Feature</th>\n",
       "    </tr>\n",
       "    </thead>\n",
       "    <tbody>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, nan%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                datetime\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "        <tr style=\"background-color: hsl(0, 100.00%, nan%); border: none;\">\n",
       "            <td style=\"padding: 0 1em 0 0.5em; text-align: right; border: none;\">\n",
       "                0\n",
       "                \n",
       "                    &plusmn; 0.0000\n",
       "                \n",
       "            </td>\n",
       "            <td style=\"padding: 0 0.5em 0 0.5em; text-align: left; border: none;\">\n",
       "                blockid\n",
       "            </td>\n",
       "        </tr>\n",
       "    \n",
       "    \n",
       "    </tbody>\n",
       "</table>\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "    \n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eli5.show_weights(permuter, top=None, feature_names=X_train.columns.tolist())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GradientBoostingRegressor(alpha=0.9, criterion='friedman_mse', init=None,\n",
       "             learning_rate=0.1, loss='ls', max_depth=3, max_features=None,\n",
       "             max_leaf_nodes=None, min_impurity_decrease=0.0,\n",
       "             min_impurity_split=None, min_samples_leaf=1,\n",
       "             min_samples_split=2, min_weight_fraction_leaf=0.0,\n",
       "             n_estimators=100, n_iter_no_change=None, presort='auto',\n",
       "             random_state=None, subsample=1.0, tol=0.0001,\n",
       "             validation_fraction=0.1, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GBmodel = GradientBoostingRegressor()\n",
    "GBmodel.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mae: 5.7258836731097064e-08\n",
      "rmse: 4.5125845779605515e-06\n"
     ]
    }
   ],
   "source": [
    "y_predGB = GBmodel.predict(X_val)\n",
    "print('mae:', mean_absolute_error(y_val, y_predGB))\n",
    "print('rmse:', np.sqrt(mean_squared_error(y_val, y_predGB)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "conda_python3",
   "language": "python",
   "name": "conda_python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
